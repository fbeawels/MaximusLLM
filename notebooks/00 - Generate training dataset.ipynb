{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 - Generate the training dataset for MaximusLLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Install the Bonito package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package is required to process the documents and create the training dataset.\n",
    "Ensure you use the 0.0.1 branch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: le chemin de destination 'bonito' existe déjà et n'est pas un répertoire vide.\n"
     ]
    }
   ],
   "source": [
    "!cd ../modules/ && git clone https://github.com/BatsResearch/bonito.git --branch v0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to change the 'setup.py' file to avoid conflicts with existing dependencies:\n",
    "\n",
    "```\n",
    "requirements = [\n",
    "    \"transformers == 4.42.0\",\n",
    "    \"datasets == 2.20.0\",\n",
    "    \"vllm == 0.5.1\",\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/franck/Sandbox/03 - Awels Engineering/MaximusLLM/modules/bonito\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers==4.42.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from bonito==0.0.1) (4.42.0)\n",
      "Requirement already satisfied: datasets==2.20.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from bonito==0.0.1) (2.20.0)\n",
      "Requirement already satisfied: vllm==0.5.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from bonito==0.0.1) (0.5.1)\n",
      "Requirement already satisfied: filelock in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (3.15.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets==2.20.0->bonito==0.0.1) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (0.23.4)\n",
      "Requirement already satisfied: packaging in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from datasets==2.20.0->bonito==0.0.1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from transformers==4.42.0->bonito==0.0.1) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from transformers==4.42.0->bonito==0.0.1) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from transformers==4.42.0->bonito==0.0.1) (0.4.3)\n",
      "Requirement already satisfied: cmake>=3.21 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (3.30.0)\n",
      "Requirement already satisfied: ninja in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (1.11.1.1)\n",
      "Requirement already satisfied: psutil in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (5.9.0)\n",
      "Requirement already satisfied: sentencepiece in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (0.2.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (9.0.0)\n",
      "Requirement already satisfied: fastapi in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (0.111.0)\n",
      "Requirement already satisfied: openai in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (1.35.10)\n",
      "Requirement already satisfied: uvicorn[standard] in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (0.30.1)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (2.6.1)\n",
      "Requirement already satisfied: pillow in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (10.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.18.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (0.20.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (7.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (0.7.0)\n",
      "Requirement already satisfied: lm-format-enforcer==0.10.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (0.10.1)\n",
      "Requirement already satisfied: outlines>=0.0.43 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (0.0.46)\n",
      "Requirement already satisfied: typing-extensions in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (4.11.0)\n",
      "Requirement already satisfied: ray>=2.9 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (2.31.0)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (12.555.43)\n",
      "Requirement already satisfied: torch==2.3.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (2.3.0)\n",
      "Requirement already satisfied: torchvision==0.18.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (0.18.0)\n",
      "Requirement already satisfied: xformers==0.0.26.post1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (0.0.26.post1)\n",
      "Requirement already satisfied: vllm-flash-attn==2.5.9 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from vllm==0.5.1->bonito==0.0.1) (2.5.9)\n",
      "Requirement already satisfied: interegular>=0.3.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from lm-format-enforcer==0.10.1->vllm==0.5.1->bonito==0.0.1) (0.3.3)\n",
      "Requirement already satisfied: sympy in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (12.5.40)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from aiohttp->datasets==2.20.0->bonito==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from aiohttp->datasets==2.20.0->bonito==0.0.1) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from aiohttp->datasets==2.20.0->bonito==0.0.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from aiohttp->datasets==2.20.0->bonito==0.0.1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from aiohttp->datasets==2.20.0->bonito==0.0.1) (1.9.4)\n",
      "Requirement already satisfied: lark in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (1.1.9)\n",
      "Requirement already satisfied: nest-asyncio in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (1.6.0)\n",
      "Requirement already satisfied: cloudpickle in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: diskcache in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (5.6.3)\n",
      "Requirement already satisfied: numba in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (0.60.0)\n",
      "Requirement already satisfied: referencing in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (0.30.2)\n",
      "Requirement already satisfied: jsonschema in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (4.21.1)\n",
      "Requirement already satisfied: pycountry in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (24.6.1)\n",
      "Requirement already satisfied: pyairports in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (2.1.1)\n",
      "Requirement already satisfied: starlette<1.0.0,>=0.30.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from prometheus-fastapi-instrumentator>=7.0.0->vllm==0.5.1->bonito==0.0.1) (0.37.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from pydantic>=2.0->vllm==0.5.1->bonito==0.0.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from pydantic>=2.0->vllm==0.5.1->bonito==0.0.1) (2.16.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from ray>=2.9->vllm==0.5.1->bonito==0.0.1) (8.1.7)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from ray>=2.9->vllm==0.5.1->bonito==0.0.1) (1.0.8)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from ray>=2.9->vllm==0.5.1->bonito==0.0.1) (4.25.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from requests>=2.32.2->datasets==2.20.0->bonito==0.0.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from requests>=2.32.2->datasets==2.20.0->bonito==0.0.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from requests>=2.32.2->datasets==2.20.0->bonito==0.0.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from requests>=2.32.2->datasets==2.20.0->bonito==0.0.1) (2024.6.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from fastapi->vllm==0.5.1->bonito==0.0.1) (0.0.4)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from fastapi->vllm==0.5.1->bonito==0.0.1) (0.27.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from fastapi->vllm==0.5.1->bonito==0.0.1) (0.0.9)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from fastapi->vllm==0.5.1->bonito==0.0.1) (5.10.0)\n",
      "Requirement already satisfied: orjson>=3.2.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from fastapi->vllm==0.5.1->bonito==0.0.1) (3.10.6)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from fastapi->vllm==0.5.1->bonito==0.0.1) (2.2.0)\n",
      "Requirement already satisfied: h11>=0.8 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from uvicorn[standard]->vllm==0.5.1->bonito==0.0.1) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from uvicorn[standard]->vllm==0.5.1->bonito==0.0.1) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from uvicorn[standard]->vllm==0.5.1->bonito==0.0.1) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from uvicorn[standard]->vllm==0.5.1->bonito==0.0.1) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from uvicorn[standard]->vllm==0.5.1->bonito==0.0.1) (0.22.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from uvicorn[standard]->vllm==0.5.1->bonito==0.0.1) (12.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from openai->vllm==0.5.1->bonito==0.0.1) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from openai->vllm==0.5.1->bonito==0.0.1) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from openai->vllm==0.5.1->bonito==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from pandas->datasets==2.20.0->bonito==0.0.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from pandas->datasets==2.20.0->bonito==0.0.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from pandas->datasets==2.20.0->bonito==0.0.1) (2024.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from email_validator>=2.0.0->fastapi->vllm==0.5.1->bonito==0.0.1) (2.6.1)\n",
      "Requirement already satisfied: typer>=0.12.3 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from fastapi-cli>=0.0.2->fastapi->vllm==0.5.1->bonito==0.0.1) (0.12.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from httpx>=0.23.0->fastapi->vllm==0.5.1->bonito==0.0.1) (1.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from jinja2->torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.20.0->bonito==0.0.1) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from jsonschema->outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (2023.7.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from jsonschema->outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (0.10.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from numba->outlines>=0.0.43->vllm==0.5.1->bonito==0.0.1) (0.43.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from sympy->torch==2.3.0->vllm==0.5.1->bonito==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm==0.5.1->bonito==0.0.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm==0.5.1->bonito==0.0.1) (13.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm==0.5.1->bonito==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm==0.5.1->bonito==0.0.1) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm==0.5.1->bonito==0.0.1) (0.1.2)\n",
      "Building wheels for collected packages: bonito\n",
      "  Building wheel for bonito (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bonito: filename=bonito-0.0.1-py3-none-any.whl size=4100 sha256=1a61831186ba7dd78e7be1a1d56fd57bec323f4f54b318f87b862dd4d3363418\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-k6z7ormx/wheels/70/79/bf/6c2ac6529bb8bd8e02588d1c16da544cc459259bda1f12e0f8\n",
      "Successfully built bonito\n",
      "Installing collected packages: bonito\n",
      "  Attempting uninstall: bonito\n",
      "    Found existing installation: bonito 0.0.1\n",
      "    Uninstalling bonito-0.0.1:\n",
      "      Successfully uninstalled bonito-0.0.1\n",
      "Successfully installed bonito-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ../modules/bonito/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Import all the required libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following libraries are required:\n",
    "\n",
    "- **Os** library for interacting with the operating system\n",
    "- **Torch** library for deep learning used to retrain the Phi 3 model\n",
    "- **Bonito** library for processing the documents and creating the training dataset\n",
    "- **Fitz** library for PDF document handling\n",
    "- **Datasets** library for handling and processing datasets\n",
    "- **Spacy** library for natural language processing\n",
    "- **Pandas** library for data manipulation and analysis\n",
    "- **HuggingFace** library for accessing models and datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import hashlib\n",
    "import torch\n",
    "import bonito\n",
    "from bonito import Bonito, SamplingParams\n",
    "import fitz\n",
    "import dotenv\n",
    "import datasets as ds\n",
    "from datasets import Dataset, DatasetDict, Value\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import huggingface_hub as hf\n",
    "from huggingface_hub import notebook_login, login\n",
    "from huggingface_hub import create_repo\n",
    "from huggingface_hub import Repository\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Spacy library for natural language processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.6.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/franck/Applications/miniconda3/envs/MaximusLLM/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import the environment variables containing the various tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Declare the functions to be used ed in the processing and creation of the training dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function opens a PDF file located at the specified path, reads the text content from each page, and concatenates all the text into a single string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from each page of a PDF file.\n",
    "\n",
    "    Parameters:\n",
    "    pdf_path (str): The file path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    str: The concatenated text extracted from all pages of the PDF.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function assumes that the `nlp` object (typically an instance of a language model from the spaCy library) is already defined and has been loaded with the appropriate language model (e.g., `nlp = spacy.load('en_core_web_sm')`). The `nlp` object must have sentence segmentation capabilities enabled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text):\n",
    "    \"\"\"\n",
    "    Splits a given text into individual sentences using natural language processing.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be split into sentences.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of strings, where each string is a sentence from the input text.\n",
    "    \n",
    "    Example:\n",
    "        >>> text = \"Hello world. This is a test.\"\n",
    "        >>> split_into_sentences(text)\n",
    "        ['Hello world.', 'This is a test.']\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function generates a unique identifier (ID) using the UUID (Universally Unique Identifier) library in Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uuid():\n",
    "    \"\"\"\n",
    "    This function generates a unique identifier (ID) using the UUID (Universally Unique Identifier) library in Python.\n",
    "\n",
    "    Steps:\n",
    "    1. Creates a new UUID using the `uuid.uuid4()` function.\n",
    "    2. Converts the UUID to a string.\n",
    "    3. Encodes the string to bytes using the UTF-8 encoding.\n",
    "    4. Creates a SHA-256 hash object using the bytes from the previous step.\n",
    "    5. Obtains the hexadecimal representation of the hash using the `hexdigest()` method.\n",
    "    6. Extracts the first 64 characters of the hexadecimal hash and returns it as the unique ID.\n",
    "\n",
    "    The function is useful for generating unique IDs for various purposes, such as identifying data records, transactions, or prompts in a system.\n",
    "    By using a cryptographic hash function (SHA-256), the function ensures that the generated IDs are highly unlikely to collide,\n",
    "    even if multiple IDs are generated simultaneously or over a long period of time.\n",
    "    \"\"\"\n",
    "    uuid_obj = uuid.uuid4()\n",
    "    uuid_str = str(uuid_obj)\n",
    "    uuid_bytes = uuid_str.encode('utf-8')\n",
    "    hash_obj = hashlib.sha256(uuid_bytes)\n",
    "    hash_str = hash_obj.hexdigest()\n",
    "    id_unique = hash_str[:64]\n",
    "    return id_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is designed to add new columns to a given dictionary (example) based on the index (idx) and two lists (prompts and prompt_ids).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns(example, idx, prompts, prompt_ids):\n",
    "    \"\"\"\n",
    "    Here's a breakdown of what it does:\n",
    "        1. It adds a new key-value pair to the dictionary where the key is 'prompt' and the value is the element from the `prompts` list at the index `idx`.\n",
    "        2. It adds another key-value pair to the dictionary where the key is 'prompt_id' and the value is the element from the `prompt_ids` list at the index `idx`.\n",
    "        3. It creates a new key-value pair in the dictionary where the key is 'messages' and the value is a list of two dictionaries. The first dictionary has 'role' as 'assistant' and 'content' as the value of 'input' from the original dictionary. The second dictionary has 'role' as 'user' and 'content' as the value of 'output' from the original dictionary.\n",
    "        4. It then removes the 'input' and 'output' keys from the dictionary.\n",
    "        5. Finally, it returns the modified dictionary.\n",
    "    \"\"\"\n",
    "    example['prompt'] = prompts[idx]\n",
    "    example['prompt_id'] = prompt_ids[idx]\n",
    "    example['messages'] = [\n",
    "        {'role': 'assistant', 'content': example['input']},\n",
    "        {'role': 'user', 'content': example['output']}\n",
    "    ]\n",
    "    # Remove the input and output columns\n",
    "    del example['input']\n",
    "    del example['output']\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, generate_prompts_and_ids, is designed to create a list of prompts and a corresponding list of unique identifiers (UUIDs) for a given dataset length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompts_and_ids(dataset_length):\n",
    "    \"\"\"\n",
    "    Here's a breakdown of what the function does:\n",
    "        1. It takes an argument dataset_length, which is the number of prompts and UUIDs to generate.\n",
    "        2. It creates a list of prompts where each prompt is a string that says \"You are the Maximo Application Suite helpful assistant and you must answer the user questions.\" This list is repeated dataset_length times.\n",
    "        3. It creates a list of UUIDs (unique identifiers) by calling the generate_uuid() function dataset_length times. Each UUID is a unique string that can be used to identify a specific prompt.\n",
    "        4. Finally, it returns a tuple containing the list of prompts and the list of UUIDs.\n",
    "    \"\"\"\n",
    "    prompts = [\"You are the Maximo Application Suite helpful assistant and you must answer the user questions.\"] * dataset_length\n",
    "    prompt_ids = [generate_uuid() for _ in range(dataset_length)]\n",
    "    return prompts, prompt_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to split a given dataset into three parts: a training dataset, an evaluation dataset, and a test dataset. The function takes three parameters: the dataset to be split, the size of the test dataset (default is 0.2 or 20% of the total dataset), and the size of the evaluation dataset (default is 0.1 or 10% of the total dataset). The size of the training dataset is calculated as the remaining portion of the dataset after subtracting the sizes of the test and evaluation datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_size=0.2, eval_size=0.1):\n",
    "    train_size = 1 - test_size - eval_size\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    train_test_dataset = dataset.train_test_split(test_size=test_size)\n",
    "\n",
    "    # Split the train set into train and eval sets\n",
    "    train_dataset = train_test_dataset['train']\n",
    "    eval_dataset = train_test_dataset['test'].train_test_split(test_size=eval_size / (eval_size + train_size))['test']\n",
    "    test_dataset = train_test_dataset['test'].train_test_split(test_size=eval_size / (eval_size + train_size))['train']\n",
    "\n",
    "    result = {\n",
    "        'train': train_dataset,\n",
    "        'eval': eval_dataset,\n",
    "        'test': test_dataset\n",
    "    }\n",
    "\n",
    "    #return Dataset.from_dict(train_dataset), Dataset.from_dict(eval_dataset), Dataset.from_dict(test_dataset)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Prepare the dataset based on the PDF document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will load the PDF file and create the dataset leveraging the Bonito LLM. Questions with multiple answers will be generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Increase the limit to 2,000,000 characters\n",
    "nlp.max_length = 2000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the text from the PDF document\n",
    "PDF_FILE = '../data/raw/master-map.pdf'\n",
    "text = extract_text_from_pdf(PDF_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the document into sentences using the split_into_sentences function\n",
    "sentences = split_into_sentences(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de phrases finalement créer + extrait de la 500ème\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15864\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhancement to delete users\n",
      "Starting in Maximo Application Suite 8.11, the system retains the details of the deleted users.\n"
     ]
    }
   ],
   "source": [
    "print(sentences[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e) Generate the synthetic dataset in (input/ output) format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now transform the sentences into a format suitable for the Hugging Face datasets library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sentence'],\n",
      "    num_rows: 15864\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Assuming sentences is a list of strings, where each string is a sentence\n",
    "data = {\"sentence\": sentences}\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the sentences have been extracted from the he PDF document, we can proceed to generate the synthetic dataset using the Bonito LLM.\n",
    "Now we initialize the Bonito model and load the dataset for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 07-08 19:49:35 llm_engine.py:169] Initializing an LLM engine (v0.5.1) with config: model='BatsResearch/bonito-v1', speculative_config=None, tokenizer='BatsResearch/bonito-v1', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=BatsResearch/bonito-v1, use_v2_block_manager=False, enable_prefix_caching=False)\n",
      "INFO 07-08 19:49:35 selector.py:172] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "INFO 07-08 19:49:35 selector.py:53] Using XFormers backend.\n",
      "INFO 07-08 19:49:52 selector.py:172] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "INFO 07-08 19:49:52 selector.py:53] Using XFormers backend.\n",
      "INFO 07-08 19:49:52 weight_utils.py:218] Using model weights format ['*.bin']\n",
      "INFO 07-08 19:50:01 model_runner.py:255] Loading model weights took 13.4966 GB\n",
      "INFO 07-08 19:50:03 gpu_executor.py:84] # GPU blocks: 2904, # CPU blocks: 2048\n",
      "INFO 07-08 19:50:05 model_runner.py:924] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 07-08 19:50:05 model_runner.py:928] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 07-08 19:50:16 model_runner.py:1117] Graph capturing finished in 11 secs.\n"
     ]
    }
   ],
   "source": [
    "bonito = Bonito(\"BatsResearch/bonito-v1\", max_model_len=16384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize the sampling parameters and generate the synthetic dataset using the extracted sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(max_tokens=256, top_p=0.95, temperature=0.5, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we create the synthetic dataset using the Bonito model by setting the 'qg' parameter which means 'Question Generation'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c663a6248144ad5a13b47ef908038e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 15864/15864 [05:14<00:00, 50.39it/s, est. speed input: 2828.05 toks/s, output: 2584.31 toks/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898702232d234abaa326e144c9ea9ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/15864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6f861032c7473daedf2bba05883ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15859 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "synthetic_dataset = bonito.generate_tasks(\n",
    "    dataset,\n",
    "    context_col=\"sentence\",\n",
    "    task_type=\"qg\", #qg : question generation\n",
    "    sampling_params=sampling_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the content of the synthetic datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input', 'output'],\n",
      "    num_rows: 15859\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# First describe the synthetic dataset\n",
    "print(synthetic_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  Write a multi-choice question for the followin...   \n",
      "1  Write a multi-choice question for the followin...   \n",
      "2  Write a multi-choice question for the followin...   \n",
      "3  Write a multi-choice question for the followin...   \n",
      "4  Write a multi-choice question for the followin...   \n",
      "\n",
      "                                              output  \n",
      "0  Question: \\nWhich is the best title of this pa...  \n",
      "1  Question: \\nWhich of the following is NOT true...  \n",
      "2  Question: \\nWhat is the main idea of the passa...  \n",
      "3  If you want to know the new features of 8.9, y...  \n",
      "4  Question: \\nWhat is the passage mainly about?\\...  \n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 rows of the datasets\n",
    "df = pd.DataFrame(synthetic_dataset)\n",
    "print(df.head(5)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f) Now transform this dataset into one which can be used to fine tune Phi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now transform the synthetic dataset into a format suitable for fine-tuning the Phi model. This involves creating a new dataset with the required input and output columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_dataset = split_dataset(synthetic_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['input', 'output'],\n",
       "     num_rows: 12687\n",
       " }),\n",
       " 'eval': Dataset({\n",
       "     features: ['input', 'output'],\n",
       "     num_rows: 397\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['input', 'output'],\n",
       "     num_rows: 2775\n",
       " })}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee7ff2c129f41299ccc0acd7b2e3039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12687 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2912bf3d337b45f8b22da526a726de71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/397 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8752404ee1a447dd851d0bd08b33e07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2775 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split in splitted_dataset.keys():\n",
    "    print(split)\n",
    "    dataset_length = len(splitted_dataset[split])\n",
    "    prompts, prompt_ids = generate_prompts_and_ids(dataset_length)\n",
    "    splitted_dataset[split] = splitted_dataset[split].map(\n",
    "        lambda example, idx: add_columns(example, idx, prompts, prompt_ids),\n",
    "        with_indices=True,\n",
    "        remove_columns=['input', 'output']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'You are the Maximo Application Suite helpful assistant and you must answer the user questions.', 'prompt_id': '6f709f1098fe8a9c8a07f885410e1375ac92a33c3ecf8c84ffa8811e7ffe0f86', 'messages': [{'content': 'Write a multi-choice question for the following article:\\nArticle: Global property values\\nSet the mxe.int.globaldir and other properties when you upgrade from Maximo Asset Management\\nto Maximo Manage.', 'role': 'assistant'}, {'content': 'Question: \\nWhat does the text tell us to do?\\nOptions:\\nA To upgrade to Maximo Manage.\\nB To set the mxe.int.globaldir property.\\nC To upgrade from Maximo Manage to Maximo Asset Management.\\nD To upgrade from Maximo Asset Management to Maximo Manage.\\nAnswer:\\nD', 'role': 'user'}]}\n"
     ]
    }
   ],
   "source": [
    "# Verify the new columns in the train split\n",
    "print(splitted_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g) Upload the new dataset to 🤗 Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First log into the Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/franck/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "login(token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository URL: https://huggingface.co/datasets/awels/maximo_admin_dataset\n"
     ]
    }
   ],
   "source": [
    "repo_name = \"awels/maximo_admin_dataset\"  # Choose a name for your dataset repository\n",
    "repo_url = create_repo(repo_name, repo_type=\"dataset\")\n",
    "print(\"Repository URL:\", repo_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now push the dataset to the HF hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e573d20302c54618bc683b8e1a24e2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf1334aa8c0412dbdc6e6c33321315f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afe78855ced42159f92b8601aef1088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/518 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fe07e312e1422ba39d7ac480272b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7ddaacf9814d1e9a79e22f6885d99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abf62a50ec34ad1ad9daf0148a41772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/518 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78b7df553fd40a7be4057b447b0da5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc56cae9939433bbc6f069852e6cd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9e943eff4d440b826fcc00e9e3bca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/518 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/awels/maximo_admin_dataset/commit/91b3b084749da7d748f7750b5d350c582dd7ac65', commit_message='Upload dataset', commit_description='', oid='91b3b084749da7d748f7750b5d350c582dd7ac65', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "splitted_dataset['train'].push_to_hub(f\"awels/maximo_admin_dataset\", split=\"train\")\n",
    "splitted_dataset['eval'].push_to_hub(f\"awels/maximo_admin_dataset\", split=\"eval\")\n",
    "splitted_dataset['test'].push_to_hub(f\"awels/maximo_admin_dataset\", split=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MaximusLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
